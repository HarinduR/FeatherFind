{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW36Qvc1p3sR",
        "outputId": "38cb4b8e-a0d8-4f4a-f9f0-37e729b448a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping /content/augmented_images.zip to /content/extracted_images/augmented_images...\n",
            "Finished unzipping /content/augmented_images.zip to /content/extracted_images/augmented_images\n",
            "Unzipping /content/augmented_images(white throated kingfisher).zip to /content/extracted_images/augmented_images(white throated kingfisher)...\n",
            "Finished unzipping /content/augmented_images(white throated kingfisher).zip to /content/extracted_images/augmented_images(white throated kingfisher)\n",
            "Unzipping /content/augmented_images(red vented bulbul).zip to /content/extracted_images/augmented_images(red vented bulbul)...\n",
            "Finished unzipping /content/augmented_images(red vented bulbul).zip to /content/extracted_images/augmented_images(red vented bulbul)\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths to your zip files\n",
        "zip_paths = [\n",
        "    \"/content/augmented_images.zip\",\n",
        "    \"/content/augmented_images(white throated kingfisher).zip\",\n",
        "    \"/content/augmented_images(red vented bulbul).zip\"\n",
        "]\n",
        "\n",
        "# Unzipping function\n",
        "def unzip_files(zip_paths, extract_to_base):\n",
        "    for zip_path in zip_paths:\n",
        "        # Get the folder name based on the zip file name\n",
        "        folder_name = os.path.splitext(os.path.basename(zip_path))[0]\n",
        "        extract_to = os.path.join(extract_to_base, folder_name)\n",
        "\n",
        "        os.makedirs(extract_to, exist_ok=True)\n",
        "        print(f\"Unzipping {zip_path} to {extract_to}...\")\n",
        "\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Finished unzipping {zip_path} to {extract_to}\")\n",
        "\n",
        "# Unzip all files to separate directories for each bird\n",
        "extracted_base_dir = \"/content/extracted_images\"\n",
        "unzip_files(zip_paths, extracted_base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSQDK1eNqQXz",
        "outputId": "51a66cac-db23-43a1-dbf2-94f3031e8b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing augmented_images...\n",
            "Processing augmented_images(red vented bulbul)...\n",
            "Processing augmented_images(white throated kingfisher)...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to split and organize datasets\n",
        "def split_and_organize_datasets(base_extracted_dir, split_base_dir, test_size=0.2, val_size=0.2):\n",
        "    # Clear or create split directories\n",
        "    if os.path.exists(split_base_dir):\n",
        "        shutil.rmtree(split_base_dir)\n",
        "    os.makedirs(split_base_dir, exist_ok=True)\n",
        "\n",
        "    # Create subdirectories for train, validation, and test\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(split_base_dir, split), exist_ok=True)\n",
        "\n",
        "    # Loop through each bird folder and split its images\n",
        "    for bird_folder in os.listdir(base_extracted_dir):\n",
        "        bird_dir = os.path.join(base_extracted_dir, bird_folder)\n",
        "        if not os.path.isdir(bird_dir):\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {bird_folder}...\")\n",
        "\n",
        "        # Get all image files in the current bird folder\n",
        "        images = os.listdir(bird_dir)\n",
        "        images = [img for img in images if img.endswith(('.jpg', '.jpeg', '.png'))]  # Filter valid image files\n",
        "\n",
        "        if len(images) == 0:\n",
        "            print(f\"No valid image files found in {bird_folder}\")\n",
        "            continue\n",
        "\n",
        "        # Split the images into train, test, and validation sets\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=42)\n",
        "        train_imgs, val_imgs = train_test_split(train_imgs, test_size=val_size, random_state=42)\n",
        "\n",
        "        # Copy images to the corresponding directories\n",
        "        for split, imgs in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
        "            split_dir = os.path.join(split_base_dir, split, bird_folder)\n",
        "            os.makedirs(split_dir, exist_ok=True)\n",
        "            for img in imgs:\n",
        "                shutil.copy(os.path.join(bird_dir, img), os.path.join(split_dir, img))\n",
        "\n",
        "# Path to your extracted dataset directory\n",
        "base_extracted_dir = \"/content/extracted_images\"\n",
        "split_base_dir = \"/content/split_datasets\"\n",
        "split_and_organize_datasets(base_extracted_dir, split_base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPNPzydMrUaI",
        "outputId": "adb6e047-bdf3-4b0e-bb3e-dee2eaff82d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1920 images belonging to 3 classes.\n",
            "Found 480 images belonging to 3 classes.\n",
            "Found 600 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Image size and batch size settings\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Create the ImageDataGenerator objects for train, validation, and test sets\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Define the directories for train, validation, and test\n",
        "train_dir = os.path.join(\"/content/split_datasets\", 'train')\n",
        "val_dir = os.path.join(\"/content/split_datasets\", 'val')\n",
        "test_dir = os.path.join(\"/content/split_datasets\", 'test')\n",
        "\n",
        "# Create data generators for train, validation, and test\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ljuzKhaesEt5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the ResNet50 model pre-trained on ImageNet, without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers on top of ResNet50\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global Average Pooling to reduce the output size\n",
        "x = Dense(128, activation='relu')(x)  # Fully connected layer with ReLU activation\n",
        "predictions = Dense(train_gen.num_classes, activation='softmax')(x)  # Output layer with softmax for multi-class classification\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers of ResNet50 (base model) to prevent training them\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLvp8i9PsUZF",
        "outputId": "4f8ff2cc-34e1-4cd5-a946-2f557244943f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 7s/step - accuracy: 0.3323 - loss: 1.1579 - val_accuracy: 0.4167 - val_loss: 1.0744\n",
            "Epoch 2/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 8s/step - accuracy: 0.3981 - loss: 1.0767 - val_accuracy: 0.4437 - val_loss: 1.0502\n",
            "Epoch 3/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 7s/step - accuracy: 0.4621 - loss: 1.0483 - val_accuracy: 0.4583 - val_loss: 1.0361\n",
            "Epoch 4/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 7s/step - accuracy: 0.4790 - loss: 1.0317 - val_accuracy: 0.4313 - val_loss: 1.0271\n",
            "Epoch 5/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 7s/step - accuracy: 0.4529 - loss: 1.0313 - val_accuracy: 0.4313 - val_loss: 1.0210\n",
            "Epoch 6/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 7s/step - accuracy: 0.4884 - loss: 1.0224 - val_accuracy: 0.4875 - val_loss: 1.0167\n",
            "Epoch 7/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 7s/step - accuracy: 0.4989 - loss: 1.0019 - val_accuracy: 0.4812 - val_loss: 1.0107\n",
            "Epoch 8/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 7s/step - accuracy: 0.4987 - loss: 1.0072 - val_accuracy: 0.5167 - val_loss: 1.0042\n",
            "Epoch 9/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 7s/step - accuracy: 0.5069 - loss: 0.9912 - val_accuracy: 0.4604 - val_loss: 0.9958\n",
            "Epoch 10/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 7s/step - accuracy: 0.5379 - loss: 0.9918 - val_accuracy: 0.4917 - val_loss: 0.9939\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average training accuracy across all epochs\n",
        "average_training_accuracy = sum(training_accuracy) / len(training_accuracy)\n",
        "print(\"Average Training Accuracy:\", average_training_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OiEEYXL1sn7",
        "outputId": "1b14196b-7610-486f-a1ba-f30a5dcfc98f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Accuracy: 0.4689583361148834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_gen)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Generate classification report\n",
        "y_true = test_gen.classes\n",
        "y_pred = np.argmax(model.predict(test_gen), axis=-1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=test_gen.class_indices.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziueuqDElfgK",
        "outputId": "c6ce0e04-d355-4753-f9c9-13e19c028dc5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 5s/step - accuracy: 0.7142 - loss: 0.8955\n",
            "Test Accuracy: 53.17%\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 5s/step\n",
            "Classification Report:\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                           augmented_images       0.51      0.83      0.63       200\n",
            "        augmented_images(red vented bulbul)       0.52      0.64      0.57       200\n",
            "augmented_images(white throated kingfisher)       0.76      0.13      0.22       200\n",
            "\n",
            "                                   accuracy                           0.53       600\n",
            "                                  macro avg       0.60      0.53      0.48       600\n",
            "                               weighted avg       0.60      0.53      0.48       600\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}