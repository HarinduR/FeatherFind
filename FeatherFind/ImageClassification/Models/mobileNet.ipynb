{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsjU_ENovdN-",
        "outputId": "a66a5d2a-7d7c-4d61-e766-746cfde113a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping /content/augmented_images.zip to /content/extracted_images/augmented_images...\n",
            "Finished unzipping /content/augmented_images.zip to /content/extracted_images/augmented_images\n",
            "Unzipping /content/augmented_images(white throated kingfisher).zip to /content/extracted_images/augmented_images(white throated kingfisher)...\n",
            "Finished unzipping /content/augmented_images(white throated kingfisher).zip to /content/extracted_images/augmented_images(white throated kingfisher)\n",
            "Unzipping /content/augmented_images(red vented bulbul).zip to /content/extracted_images/augmented_images(red vented bulbul)...\n",
            "Finished unzipping /content/augmented_images(red vented bulbul).zip to /content/extracted_images/augmented_images(red vented bulbul)\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths to your zip files\n",
        "zip_paths = [\n",
        "    \"/content/augmented_images.zip\",\n",
        "    \"/content/augmented_images(white throated kingfisher).zip\",\n",
        "    \"/content/augmented_images(red vented bulbul).zip\"\n",
        "]\n",
        "\n",
        "# Unzipping function\n",
        "def unzip_files(zip_paths, extract_to_base):\n",
        "    for zip_path in zip_paths:\n",
        "        # Get the folder name based on the zip file name\n",
        "        folder_name = os.path.splitext(os.path.basename(zip_path))[0]\n",
        "        extract_to = os.path.join(extract_to_base, folder_name)\n",
        "\n",
        "        os.makedirs(extract_to, exist_ok=True)\n",
        "        print(f\"Unzipping {zip_path} to {extract_to}...\")\n",
        "\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Finished unzipping {zip_path} to {extract_to}\")\n",
        "\n",
        "# Unzip all files to separate directories for each bird\n",
        "extracted_base_dir = \"/content/extracted_images\"\n",
        "unzip_files(zip_paths, extracted_base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXroac6Ny_Gf",
        "outputId": "db87d462-57f4-49ed-b8d9-b09eff5abcaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing augmented_images(red vented bulbul)...\n",
            "Processing augmented_images(white throated kingfisher)...\n",
            "Processing augmented_images...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to split and organize datasets\n",
        "def split_and_organize_datasets(base_extracted_dir, split_base_dir, test_size=0.2, val_size=0.2):\n",
        "    # Clear or create split directories\n",
        "    if os.path.exists(split_base_dir):\n",
        "        shutil.rmtree(split_base_dir)\n",
        "    os.makedirs(split_base_dir, exist_ok=True)\n",
        "\n",
        "    # Create subdirectories for train, validation, and test\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(split_base_dir, split), exist_ok=True)\n",
        "\n",
        "    # Loop through each bird folder and split its images\n",
        "    for bird_folder in os.listdir(base_extracted_dir):\n",
        "        bird_dir = os.path.join(base_extracted_dir, bird_folder)\n",
        "        if not os.path.isdir(bird_dir):\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {bird_folder}...\")\n",
        "\n",
        "        # Get all image files in the current bird folder\n",
        "        images = os.listdir(bird_dir)\n",
        "        images = [img for img in images if img.endswith(('.jpg', '.jpeg', '.png'))]  # Filter valid image files\n",
        "\n",
        "        if len(images) == 0:\n",
        "            print(f\"No valid image files found in {bird_folder}\")\n",
        "            continue\n",
        "\n",
        "        # Split the images into train, test, and validation sets\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=42)\n",
        "        train_imgs, val_imgs = train_test_split(train_imgs, test_size=val_size, random_state=42)\n",
        "\n",
        "        # Copy images to the corresponding directories\n",
        "        for split, imgs in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
        "            split_dir = os.path.join(split_base_dir, split, bird_folder)\n",
        "            os.makedirs(split_dir, exist_ok=True)\n",
        "            for img in imgs:\n",
        "                shutil.copy(os.path.join(bird_dir, img), os.path.join(split_dir, img))\n",
        "\n",
        "# Path to your extracted dataset directory\n",
        "base_extracted_dir = \"/content/extracted_images\"\n",
        "split_base_dir = \"/content/split_datasets\"\n",
        "split_and_organize_datasets(base_extracted_dir, split_base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O4CPY0kzBTE",
        "outputId": "98844f1b-b0e6-4842-b058-14ed5bf7e108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1920 images belonging to 3 classes.\n",
            "Found 480 images belonging to 3 classes.\n",
            "Found 600 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Image size and batch size settings\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Create the ImageDataGenerator objects for train, validation, and test sets\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Define the directories for train, validation, and test\n",
        "train_dir = os.path.join(\"/content/split_datasets\", 'train')\n",
        "val_dir = os.path.join(\"/content/split_datasets\", 'val')\n",
        "test_dir = os.path.join(\"/content/split_datasets\", 'test')\n",
        "\n",
        "# Create data generators for train, validation, and test\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1u4jbMtzDBJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the MobileNetV2 model with pre-trained weights\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create the full model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLW-ldOuzE5N",
        "outputId": "d91674af-2886-4811-cf58-d4921b9e5ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.6682 - val_accuracy: 0.9563 - val_loss: 0.1967\n",
            "Epoch 2/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - accuracy: 0.9642 - loss: 0.1480 - val_accuracy: 0.9646 - val_loss: 0.1299\n",
            "Epoch 3/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - accuracy: 0.9685 - loss: 0.1141 - val_accuracy: 0.9729 - val_loss: 0.1026\n",
            "Epoch 4/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 0.9864 - loss: 0.0681 - val_accuracy: 0.9792 - val_loss: 0.0879\n",
            "Epoch 5/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.0551 - val_accuracy: 0.9792 - val_loss: 0.0819\n",
            "Epoch 6/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.9949 - loss: 0.0410 - val_accuracy: 0.9854 - val_loss: 0.0698\n",
            "Epoch 7/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.9957 - loss: 0.0359 - val_accuracy: 0.9875 - val_loss: 0.0684\n",
            "Epoch 8/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 2s/step - accuracy: 0.9973 - loss: 0.0319 - val_accuracy: 0.9896 - val_loss: 0.0615\n",
            "Epoch 9/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 2s/step - accuracy: 0.9998 - loss: 0.0229 - val_accuracy: 0.9917 - val_loss: 0.0573\n",
            "Epoch 10/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9992 - loss: 0.0219 - val_accuracy: 0.9917 - val_loss: 0.0571\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EINygqfWzHYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af92816d-9b1c-4846-81d2-3f59d6323e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Accuracy: 0.9740\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.9865 - loss: 0.0360\n",
            "Test Accuracy: 98.33%\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step\n",
            "Classification Report:\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                           augmented_images       0.99      0.99      0.99       200\n",
            "        augmented_images(red vented bulbul)       0.99      0.97      0.98       200\n",
            "augmented_images(white throated kingfisher)       0.97      0.99      0.98       200\n",
            "\n",
            "                                   accuracy                           0.98       600\n",
            "                                  macro avg       0.98      0.98      0.98       600\n",
            "                               weighted avg       0.98      0.98      0.98       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Calculate the average training accuracy across all epochs\n",
        "average_training_accuracy = sum(history.history['accuracy']) / len(history.history['accuracy'])\n",
        "\n",
        "# Print the result\n",
        "print(f\"Average Training Accuracy: {average_training_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_gen, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Generate classification report\n",
        "y_true = test_gen.classes  # Ground truth labels\n",
        "y_pred = np.argmax(model.predict(test_gen), axis=-1)  # Predicted labels\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=test_gen.class_indices.keys()))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}