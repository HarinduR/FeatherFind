{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsjU_ENovdN-",
        "outputId": "26316866-f10e-47ec-d30a-e00d0188c357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping /content/augmented_images.zip to /content/extracted_images/augmented_images...\n",
            "Finished unzipping /content/augmented_images.zip to /content/extracted_images/augmented_images\n",
            "Unzipping /content/augmented_images(white throated kingfisher).zip to /content/extracted_images/augmented_images(white throated kingfisher)...\n",
            "Finished unzipping /content/augmented_images(white throated kingfisher).zip to /content/extracted_images/augmented_images(white throated kingfisher)\n",
            "Unzipping /content/augmented_images(red vented bulbul).zip to /content/extracted_images/augmented_images(red vented bulbul)...\n",
            "Finished unzipping /content/augmented_images(red vented bulbul).zip to /content/extracted_images/augmented_images(red vented bulbul)\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths to your zip files\n",
        "zip_paths = [\n",
        "    \"/content/augmented_images.zip\",\n",
        "    \"/content/augmented_images(white throated kingfisher).zip\",\n",
        "    \"/content/augmented_images(red vented bulbul).zip\"\n",
        "]\n",
        "\n",
        "# Unzipping function\n",
        "def unzip_files(zip_paths, extract_to_base):\n",
        "    for zip_path in zip_paths:\n",
        "        # Get the folder name based on the zip file name\n",
        "        folder_name = os.path.splitext(os.path.basename(zip_path))[0]\n",
        "        extract_to = os.path.join(extract_to_base, folder_name)\n",
        "\n",
        "        os.makedirs(extract_to, exist_ok=True)\n",
        "        print(f\"Unzipping {zip_path} to {extract_to}...\")\n",
        "\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Finished unzipping {zip_path} to {extract_to}\")\n",
        "\n",
        "# Unzip all files to separate directories for each bird\n",
        "extracted_base_dir = \"/content/extracted_images\"\n",
        "unzip_files(zip_paths, extracted_base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXroac6Ny_Gf",
        "outputId": "c0a1f801-5080-499b-a543-93017c5fd027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing augmented_images(red vented bulbul)...\n",
            "Processing augmented_images(white throated kingfisher)...\n",
            "Processing augmented_images...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to split and organize datasets\n",
        "def split_and_organize_datasets(base_extracted_dir, split_base_dir, test_size=0.2, val_size=0.2):\n",
        "    # Clear or create split directories\n",
        "    if os.path.exists(split_base_dir):\n",
        "        shutil.rmtree(split_base_dir)\n",
        "    os.makedirs(split_base_dir, exist_ok=True)\n",
        "\n",
        "    # Create subdirectories for train, validation, and test\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(split_base_dir, split), exist_ok=True)\n",
        "\n",
        "    # Loop through each bird folder and split its images\n",
        "    for bird_folder in os.listdir(base_extracted_dir):\n",
        "        bird_dir = os.path.join(base_extracted_dir, bird_folder)\n",
        "        if not os.path.isdir(bird_dir):\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {bird_folder}...\")\n",
        "\n",
        "        # Get all image files in the current bird folder\n",
        "        images = os.listdir(bird_dir)\n",
        "        images = [img for img in images if img.endswith(('.jpg', '.jpeg', '.png'))]  # Filter valid image files\n",
        "\n",
        "        if len(images) == 0:\n",
        "            print(f\"No valid image files found in {bird_folder}\")\n",
        "            continue\n",
        "\n",
        "        # Split the images into train, test, and validation sets\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
        "        train_imgs, val_imgs = train_test_split(train_imgs, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Copy images to the corresponding directories\n",
        "        for split, imgs in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
        "            split_dir = os.path.join(split_base_dir, split, bird_folder)\n",
        "            os.makedirs(split_dir, exist_ok=True)\n",
        "            for img in imgs:\n",
        "                shutil.copy(os.path.join(bird_dir, img), os.path.join(split_dir, img))\n",
        "\n",
        "# Path to your extracted dataset directory\n",
        "base_extracted_dir = \"/content/extracted_images\"\n",
        "split_base_dir = \"/content/split_datasets\"\n",
        "split_and_organize_datasets(base_extracted_dir, split_base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O4CPY0kzBTE",
        "outputId": "9dcb7bc8-7203-41e7-c62f-b4b6f22df500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1920 images belonging to 3 classes.\n",
            "Found 480 images belonging to 3 classes.\n",
            "Found 600 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Image size and batch size settings\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Create the ImageDataGenerator objects for train, validation, and test sets\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Define the directories for train, validation, and test\n",
        "train_dir = os.path.join(\"/content/split_datasets\", 'train')\n",
        "val_dir = os.path.join(\"/content/split_datasets\", 'val')\n",
        "test_dir = os.path.join(\"/content/split_datasets\", 'test')\n",
        "\n",
        "# Create data generators for train, validation, and test\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1u4jbMtzDBJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the MobileNetV2 model with pre-trained weights\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Unfreeze the last 15 layers for fine-tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add L2 regularization to base model layers\n",
        "for layer in base_model.layers[-15:]:\n",
        "    if hasattr(layer, 'kernel_regularizer'):\n",
        "        layer.kernel_regularizer = tf.keras.regularizers.l2(0.01)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)),  # Increased neurons\n",
        "    Dropout(0.2),  # Reduced dropout\n",
        "    Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with label smoothing\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),  # Increased learning rate\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),  # Label smoothing to reduce overconfidence\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLW-ldOuzE5N",
        "outputId": "87e28cf6-1424-4c3b-93f6-6da2d682a88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5564 - loss: 5.5897 - val_accuracy: 0.8292 - val_loss: 5.2099\n",
            "Epoch 2/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.8428 - loss: 5.1281 - val_accuracy: 0.8813 - val_loss: 5.0171\n",
            "Epoch 3/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - accuracy: 0.9075 - loss: 4.9301 - val_accuracy: 0.9125 - val_loss: 4.8886\n",
            "Epoch 4/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.9144 - loss: 4.8252 - val_accuracy: 0.9125 - val_loss: 4.7935\n",
            "Epoch 5/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - accuracy: 0.9357 - loss: 4.7084 - val_accuracy: 0.9208 - val_loss: 4.7027\n",
            "Epoch 6/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.9517 - loss: 4.6219 - val_accuracy: 0.9292 - val_loss: 4.6279\n",
            "Epoch 7/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - accuracy: 0.9579 - loss: 4.5558 - val_accuracy: 0.9396 - val_loss: 4.5520\n",
            "Epoch 8/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.9587 - loss: 4.4792 - val_accuracy: 0.9542 - val_loss: 4.4804\n",
            "Epoch 9/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.9661 - loss: 4.4258 - val_accuracy: 0.9583 - val_loss: 4.4087\n",
            "Epoch 10/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.9699 - loss: 4.3558 - val_accuracy: 0.9604 - val_loss: 4.3469\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EINygqfWzHYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea101015-3111-49cf-a7bb-70025c01aff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Accuracy: 0.9081\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.9730 - loss: 4.3031\n",
            "Test Accuracy: 94.67%\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step\n",
            "Classification Report:\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                           augmented_images       0.89      0.99      0.94       200\n",
            "        augmented_images(red vented bulbul)       0.98      0.95      0.97       200\n",
            "augmented_images(white throated kingfisher)       0.97      0.90      0.94       200\n",
            "\n",
            "                                   accuracy                           0.95       600\n",
            "                                  macro avg       0.95      0.95      0.95       600\n",
            "                               weighted avg       0.95      0.95      0.95       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Calculate the average training accuracy across all epochs\n",
        "average_training_accuracy = sum(history.history['accuracy']) / len(history.history['accuracy'])\n",
        "\n",
        "# Print the result\n",
        "print(f\"Average Training Accuracy: {average_training_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_gen, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Generate classification report\n",
        "y_true = test_gen.classes  # Ground truth labels\n",
        "y_pred = np.argmax(model.predict(test_gen), axis=-1)  # Predicted labels\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=test_gen.class_indices.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/bird_classification_model.h5\")  # Saves the model to the specified path\n",
        "from google.colab import files\n",
        "files.download(\"/content/bird_classification_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "e8KHhMLq1Bd9",
        "outputId": "27ca6a95-7292-45e7-a1fa-6d74c6a5bf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c0b345f9-e762-42db-9203-135b6799631c\", \"bird_classification_model.h5\", 17247552)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model (if not already loaded)\n",
        "# model = tf.keras.models.load_model('path_to_your_trained_model')\n",
        "\n",
        "# Path to the image you want to classify\n",
        "image_path = '/content/download (1).jpeg'\n",
        "\n",
        "# Load the image and resize it to the target size used during training (224x224 in your case)\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Rescale the image (normalize it to the range [0, 1])\n",
        "img_array = img_array / 255.0\n",
        "\n",
        "# Expand the dimensions to match the input shape of the model (batch size, height, width, channels)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Make the prediction\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Get the class with the highest predicted probability\n",
        "predicted_class = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Get the class label from the class indices\n",
        "class_labels = list(train_gen.class_indices.keys())\n",
        "predicted_class_label = class_labels[predicted_class[0]]\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3eykkISRAbU",
        "outputId": "e47cb6e7-93f5-4aae-bb03-531ee5f4d97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Predicted Class: augmented_images(red vented bulbul)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model (if not already loaded)\n",
        "# model = tf.keras.models.load_model('path_to_your_trained_model')\n",
        "\n",
        "# Path to the image you want to classify\n",
        "image_path = '/content/download (2).jpeg'\n",
        "\n",
        "# Load the image and resize it to the target size used during training (224x224 in your case)\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Rescale the image (normalize it to the range [0, 1])\n",
        "img_array = img_array / 255.0\n",
        "\n",
        "# Expand the dimensions to match the input shape of the model (batch size, height, width, channels)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Make the prediction\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Get the class with the highest predicted probability\n",
        "predicted_class = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Get the probability of the predicted class\n",
        "predicted_probability = predictions[0][predicted_class[0]]\n",
        "\n",
        "# Define a threshold for confidence (e.g., 0.7 or 70%)\n",
        "confidence_threshold = 0.7\n",
        "\n",
        "if predicted_probability < confidence_threshold:\n",
        "    print(\"Cannot identify with high confidence.\")\n",
        "else:\n",
        "    # Get the class label from the class indices\n",
        "    class_labels = list(train_gen.class_indices.keys())\n",
        "    predicted_class_label = class_labels[predicted_class[0]]\n",
        "    print(f\"Predicted Class: {predicted_class_label} with confidence: {predicted_probability:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mlbA0UnTJSX",
        "outputId": "bd064bb0-3883-4bd6-8cc9-113b0090af71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Cannot identify with high confidence.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}