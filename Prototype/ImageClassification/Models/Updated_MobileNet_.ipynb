{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxXuVhOEpcwn"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths to your zip files\n",
        "zip_paths = [\n",
        "    \"/content/Blue Tailed Bee Eater.zip\",\n",
        "    \"/content/Red Vented Bul Bul.zip\",\n",
        "    \"/content/White throted kingfisher.zip\"\n",
        "]\n",
        "\n",
        "# Unzipping function\n",
        "def unzip_files(zip_paths, extract_to_base):\n",
        "    for zip_path in zip_paths:\n",
        "        # Get the folder name based on the zip file name\n",
        "        folder_name = os.path.splitext(os.path.basename(zip_path))[0]\n",
        "        extract_to = os.path.join(extract_to_base, folder_name)\n",
        "\n",
        "        os.makedirs(extract_to, exist_ok=True)\n",
        "        print(f\"Unzipping {zip_path} to {extract_to}...\")\n",
        "\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Finished unzipping {zip_path} to {extract_to}\")\n",
        "\n",
        "# Unzip all files to separate directories for each bird\n",
        "extracted_base_dir = \"/content/extracted_images\"\n",
        "unzip_files(zip_paths, extracted_base_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfV1PC39qNYV",
        "outputId": "d0e8725d-4cc0-4806-f9da-7436f060f0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping /content/Blue Tailed Bee Eater.zip to /content/extracted_images/Blue Tailed Bee Eater...\n",
            "Finished unzipping /content/Blue Tailed Bee Eater.zip to /content/extracted_images/Blue Tailed Bee Eater\n",
            "Unzipping /content/Red Vented Bul Bul.zip to /content/extracted_images/Red Vented Bul Bul...\n",
            "Finished unzipping /content/Red Vented Bul Bul.zip to /content/extracted_images/Red Vented Bul Bul\n",
            "Unzipping /content/White throted kingfisher.zip to /content/extracted_images/White throted kingfisher...\n",
            "Finished unzipping /content/White throted kingfisher.zip to /content/extracted_images/White throted kingfisher\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split and organize datasets\n",
        "def split_and_organize_datasets(base_extracted_dir, split_base_dir, test_size=0.2, val_size=0.2):\n",
        "    if os.path.exists(split_base_dir):\n",
        "        shutil.rmtree(split_base_dir)\n",
        "    os.makedirs(split_base_dir, exist_ok=True)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(split_base_dir, split), exist_ok=True)\n",
        "\n",
        "    for bird_folder in os.listdir(base_extracted_dir):\n",
        "        bird_dir = os.path.join(base_extracted_dir, bird_folder)\n",
        "        if not os.path.isdir(bird_dir):\n",
        "            continue\n",
        "        images = [img for img in os.listdir(bird_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if len(images) == 0:\n",
        "            continue\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=42)\n",
        "        train_imgs, val_imgs = train_test_split(train_imgs, test_size=val_size, random_state=42)\n",
        "        for split, imgs in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
        "            split_dir = os.path.join(split_base_dir, split, bird_folder)\n",
        "            os.makedirs(split_dir, exist_ok=True)\n",
        "            for img in imgs:\n",
        "                shutil.copy(os.path.join(bird_dir, img), os.path.join(split_dir, img))\n",
        "\n",
        "# Split dataset\n",
        "split_base_dir = \"/content/split_datasets\"\n",
        "split_and_organize_datasets(extracted_base_dir, split_base_dir)\n"
      ],
      "metadata": {
        "id": "BiooEqAaquJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to augment training data by flipping images\n",
        "def augment_training_data(train_dir):\n",
        "    for bird_folder in os.listdir(train_dir):\n",
        "        bird_folder_path = os.path.join(train_dir, bird_folder)\n",
        "        if not os.path.isdir(bird_folder_path):\n",
        "            continue\n",
        "        for img_name in os.listdir(bird_folder_path):\n",
        "            img_path = os.path.join(bird_folder_path, img_name)\n",
        "            if img_path.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img = load_img(img_path)\n",
        "                img_array = img_to_array(img)\n",
        "                flipped_img_array = np.fliplr(img_array)  # Flip image\n",
        "                flipped_img = array_to_img(flipped_img_array)\n",
        "                flipped_img.save(os.path.join(bird_folder_path, f\"flipped_{img_name}\"))\n",
        "\n",
        "# Augment training data\n",
        "train_dir = os.path.join(split_base_dir, 'train')\n",
        "augment_training_data(train_dir)\n",
        "\n",
        "# ImageDataGenerator setup\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')\n",
        "val_gen = val_datagen.flow_from_directory(os.path.join(split_base_dir, 'val'), target_size=img_size, batch_size=batch_size, class_mode='categorical')\n",
        "test_gen = test_datagen.flow_from_directory(os.path.join(split_base_dir, 'test'), target_size=img_size, batch_size=batch_size, class_mode='categorical', shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gghnOnDkq1KP",
        "outputId": "b64cf8b3-a20e-464a-87d5-a94c22b96a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1920 images belonging to 3 classes.\n",
            "Found 240 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the MobileNetV2 model with pre-trained weights\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Unfreeze the last 15 layers for fine-tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add L2 regularization to base model layers\n",
        "for layer in base_model.layers[-15:]:\n",
        "    if hasattr(layer, 'kernel_regularizer'):\n",
        "        layer.kernel_regularizer = tf.keras.regularizers.l2(0.01)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)),  # Increased neurons\n",
        "    Dropout(0.2),  # Reduced dropout\n",
        "    Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with label smoothing\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),  # Increased learning rate\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),  # Label smoothing to reduce overconfidence\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "0TjA76ihq3WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "epochs = 10\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=epochs, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v_cXKgnrAro",
        "outputId": "f96b7113-f1ed-45b1-aa9f-cc83ff909e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.4334 - loss: 5.9807 - val_accuracy: 0.6167 - val_loss: 5.4720\n",
            "Epoch 2/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.7485 - loss: 5.2686 - val_accuracy: 0.7167 - val_loss: 5.2247\n",
            "Epoch 3/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8811 - loss: 5.0047 - val_accuracy: 0.7333 - val_loss: 5.1110\n",
            "Epoch 4/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.9217 - loss: 4.8608 - val_accuracy: 0.7917 - val_loss: 4.9975\n",
            "Epoch 5/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9291 - loss: 4.7757 - val_accuracy: 0.8042 - val_loss: 4.9052\n",
            "Epoch 6/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9427 - loss: 4.6943 - val_accuracy: 0.8375 - val_loss: 4.8212\n",
            "Epoch 7/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9536 - loss: 4.6307 - val_accuracy: 0.8542 - val_loss: 4.7351\n",
            "Epoch 8/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9549 - loss: 4.5640 - val_accuracy: 0.8750 - val_loss: 4.6687\n",
            "Epoch 9/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9712 - loss: 4.4890 - val_accuracy: 0.8792 - val_loss: 4.5891\n",
            "Epoch 10/10\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9726 - loss: 4.4317 - val_accuracy: 0.8875 - val_loss: 4.5210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "average_training_accuracy = sum(history.history['accuracy']) / len(history.history['accuracy'])\n",
        "print(f\"Average Training Accuracy: {average_training_accuracy * 100:.2f}%\")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_gen, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "y_true = test_gen.classes\n",
        "y_pred = np.argmax(model.predict(test_gen), axis=-1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=test_gen.class_indices.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMY18zBGrDog",
        "outputId": "a155b0c1-8ca5-4351-f56d-caebd51a55b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Accuracy: 88.22%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9429 - loss: 4.4047\n",
            "Test Accuracy: 88.00%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "   Blue Tailed Bee Eater       0.75      1.00      0.86       100\n",
            "      Red Vented Bul Bul       0.99      0.87      0.93       100\n",
            "White throted kingfisher       0.97      0.77      0.86       100\n",
            "\n",
            "                accuracy                           0.88       300\n",
            "               macro avg       0.91      0.88      0.88       300\n",
            "            weighted avg       0.91      0.88      0.88       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/bird_classification_model.h5\")  # Saves the model\n",
        "from google.colab import files\n",
        "files.download(\"/content/bird_classification_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Mq5dnGnqvFR8",
        "outputId": "24c1c567-25ba-4c32-c5b6-3e97a4eb8d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ad59b4c1-6d6f-4fd8-ad63-4290c34bd39b\", \"bird_classification_model.h5\", 17247552)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}